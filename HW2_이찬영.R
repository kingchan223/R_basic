# 문제 1
#
#                                       |                Actual(실제 값)
#                                       |    Fraud(사기)    |  Non-Fraud(사기 아님)
#  -------------------------------------------------------------------------------------
#                  Fraud(사기)          |        30          |      58
#  Predication     ---------------------------------------------------------------------
#                  Non-Fraud(사기 X)    |        32          |      920
#  -------------------------------------------------------------------------------------
#
# 오차율 : (fraud라고 예측했지만 실제로는 fraud가 아닌 데이터 개수) + (fraud가 아니라고 예측했지만 실제로는 fraud인 데이터 개수) / 예측한 모든 데이터 개수 
# = 58 + 32 / 30 + 58 + 32 + 920 = 90/1040 =0.86538


#문제 2
# a)
# 사기 분류 cutoff 값을 올리면 사기(Fraud)로 분류하는 데이터가 적어져 사기로 분류하는 정확도는 올라가서 사기 분류 오차율은 내려갈 것이다.
# 반대로 cutoff값을 내리면 사기로 분류하는 데이터가 많아지고 사기 분류 정확도는 내려가고 결국 사기 분류 오차율이 커질 것이다.
#
# b)
# 사기 분류 cutoff값을 올리면 비사기(Non-Fraud)로 분류하는 데이터가 많아지고 비사기 분류 정확도는 내려가면서 자연히 비사기 분류 오차율은 올라간다.
# cutoff값을 내리면 비사기 분류 데이터는 적어지고 비사기 분류 정확도가 올라가면서 비사기 분류 오차율은 내려갈 것이다.


#문제 3)
install.packages('caret')
library(caret)
Propensity<-c(0.03, 0.52, 0.38, 0.82, 0.33, 0.42, 0.55, 0.59, 0.09, 0.21, 0.43, 0.04, 0.08, 0.13, 0.01, 0.79, 0.42, 0.29, 0.08, 0.02)
Actual<-    c(0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0,    0)
df <- data.frame(Propensity,Actual)
confusionMatrix(as.factor(ifelse(df$Propensity>0.25, '1', '0')), as.factor(df$Actual))
confusionMatrix(as.factor(ifelse(df$Propensity>0.5, '1', '0')), as.factor(df$Actual))
confusionMatrix(as.factor(ifelse(df$Propensity>0.75, '1', '0')), as.factor(df$Actual))




